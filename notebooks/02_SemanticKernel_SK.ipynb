{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: semantic-kernel in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (1.17.1)\n",
      "Requirement already satisfied: pydantic-settings~=2.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (2.7.1)\n",
      "Requirement already satisfied: pybars4~=0.9 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (0.9.13)\n",
      "Requirement already satisfied: jinja2~=3.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (3.1.5)\n",
      "Requirement already satisfied: aiohttp~=3.8 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (3.11.11)\n",
      "Requirement already satisfied: azure-identity~=1.13 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (1.19.0)\n",
      "Requirement already satisfied: nest-asyncio~=1.6 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (1.6.0)\n",
      "Requirement already satisfied: prance~=23.6.21.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (23.6.21.0)\n",
      "Requirement already satisfied: cloudevents~=1.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (1.11.0)\n",
      "Requirement already satisfied: defusedxml~=0.7 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: openai~=1.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (1.58.1)\n",
      "Requirement already satisfied: opentelemetry-api~=1.24 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk~=1.24 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (1.29.0)\n",
      "Requirement already satisfied: pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (2.10.4)\n",
      "Requirement already satisfied: numpy>=1.25.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (2.2.1)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from semantic-kernel) (0.19.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (24.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.18.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (1.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (2.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from aiohttp~=3.8->semantic-kernel) (0.2.1)\n",
      "Requirement already satisfied: azure-core>=1.31.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.32.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (4.12.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (1.31.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from azure-identity~=1.13->semantic-kernel) (44.0.0)\n",
      "Requirement already satisfied: deprecation<3.0,>=2.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from cloudevents~=1.0->semantic-kernel) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from jinja2~=3.1->semantic-kernel) (3.0.2)\n",
      "Requirement already satisfied: sniffio in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openai~=1.0->semantic-kernel) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openai~=1.0->semantic-kernel) (1.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openai~=1.0->semantic-kernel) (0.8.2)\n",
      "Requirement already satisfied: tqdm>4 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openai~=1.0->semantic-kernel) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openai~=1.0->semantic-kernel) (0.28.1)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.3.3)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.6.2)\n",
      "Requirement already satisfied: isodate in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.2)\n",
      "Requirement already satisfied: parse in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (1.20.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (0.7.1)\n",
      "Requirement already satisfied: more-itertools in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (10.5.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (4.23.0)\n",
      "Requirement already satisfied: werkzeug in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel) (3.1.3)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from opentelemetry-api~=1.24->semantic-kernel) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from opentelemetry-sdk~=1.24->semantic-kernel) (0.50b0)\n",
      "Requirement already satisfied: chardet>=3.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (5.2.0)\n",
      "Requirement already satisfied: six~=1.15 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: requests>=2.25 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (2.32.3)\n",
      "Requirement already satisfied: packaging>=21.3 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (24.2)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from prance~=23.6.21.0->semantic-kernel) (0.18.8)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from pybars4~=0.9->semantic-kernel) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.11,>=2.0->semantic-kernel) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from pydantic-settings~=2.0->semantic-kernel) (1.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai~=1.0->semantic-kernel) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.12 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api~=1.24->semantic-kernel) (1.17.0)\n",
      "Requirement already satisfied: certifi in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.0->semantic-kernel) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api~=1.24->semantic-kernel) (3.21.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.22.3)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (0.4.3)\n",
      "Requirement already satisfied: PyYAML>=5.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel) (6.0.2)\n",
      "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from msal>=1.30.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: portalocker<3,>=1.4 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (2.10.1)\n",
      "Requirement already satisfied: rfc3339-validator in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel) (0.1.4)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel) (1.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from requests>=2.25->prance~=23.6.21.0->semantic-kernel) (2.3.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance~=23.6.21.0->semantic-kernel) (0.2.12)\n",
      "Requirement already satisfied: colorama in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from tqdm>4->openai~=1.0->semantic-kernel) (0.4.6)\n",
      "Requirement already satisfied: pycparser in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity~=1.13->semantic-kernel) (2.22)\n",
      "Requirement already satisfied: pywin32>=226 in f:\\01_learning\\semantickernel\\venv\\lib\\site-packages (from portalocker<3,>=1.4->msal-extensions>=1.2.0->azure-identity~=1.13->semantic-kernel) (308)\n"
     ]
    }
   ],
   "source": [
    "! pip install semantic-kernel -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "azure_openai_version = config.get('azureOpenAiVersion')\n",
    "azure_openai_endpoint = config.get('azureOpenAiEndpoint')\n",
    "azure_openai_key = config.get('azureOpenAiKey')\n",
    "azure_openai_deployment_name = config.get('azureOpenAiDeploymentName') #model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add Azure OpenAI chat completion\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    deployment_name=azure_openai_deployment_name,\n",
    "    api_key=azure_openai_key,\n",
    "    base_url=azure_openai_endpoint,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set the logging level for  semantic_kernel.kernel to DEBUG.\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s - %(name)s:%(lineno)d - %(levelname)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logging.getLogger(\"kernel\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class LightsPlugin:\n",
    "    lights = [\n",
    "        {\"id\": 1, \"name\": \"Table Lamp\", \"is_on\": False},\n",
    "        {\"id\": 2, \"name\": \"Porch light\", \"is_on\": False},\n",
    "        {\"id\": 3, \"name\": \"Chandelier\", \"is_on\": True},\n",
    "    ]\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"get_lights\",\n",
    "        description=\"Gets a list of lights and their current state\",\n",
    "    )\n",
    "    def get_state(\n",
    "        self,\n",
    "    ) -> Annotated[str, \"the output is a string\"]:\n",
    "        \"\"\"Gets a list of lights and their current state.\"\"\"\n",
    "        return self.lights\n",
    "\n",
    "    @kernel_function(\n",
    "        name=\"change_state\",\n",
    "        description=\"Changes the state of the light\",\n",
    "    )\n",
    "    def change_state(\n",
    "        self,\n",
    "        id: int,\n",
    "        is_on: bool,\n",
    "    ) -> Annotated[str, \"the output is a string\"]:\n",
    "        \"\"\"Changes the state of the light.\"\"\"\n",
    "        for light in self.lights:\n",
    "            if light[\"id\"] == id:\n",
    "                light[\"is_on\"] = is_on\n",
    "                return light\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='Lights', description=None, functions={'change_state': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='change_state', plugin_name='Lights', description='Changes the state of the light', parameters=[KernelParameterMetadata(name='id', description=None, default_value=None, type_='int', is_required=True, type_object=<class 'int'>, schema_data={'type': 'integer'}, include_in_function_choices=True), KernelParameterMetadata(name='is_on', description=None, default_value=None, type_='bool', is_required=True, type_object=<class 'bool'>, schema_data={'type': 'boolean'}, include_in_function_choices=True)], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='the output is a string', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'the output is a string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x000002B2DC693AF0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x000002B2DC691FF0>, method=<bound method LightsPlugin.change_state of <__main__.LightsPlugin object at 0x000002B2C223E3E0>>, stream_method=None), 'get_lights': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='get_lights', plugin_name='Lights', description='Gets a list of lights and their current state', parameters=[], is_prompt=False, is_asynchronous=False, return_parameter=KernelParameterMetadata(name='return', description='the output is a string', default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string', 'description': 'the output is a string'}, include_in_function_choices=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x000002B2DC691FC0>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x000002B2DC692020>, method=<bound method LightsPlugin.get_state of <__main__.LightsPlugin object at 0x000002B2C223E3E0>>, stream_method=None)})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the plugin to the kernel\n",
    "kernel.add_plugin(\n",
    "    LightsPlugin(),\n",
    "    plugin_name=\"Lights\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution_settings = AzureChatPromptExecutionSettings()\n",
    "# execution_settings.function_call_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "from semantic_kernel.connectors.ai.prompt_execution_settings import FunctionChoiceBehavior\n",
    "\n",
    "execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=\"chat\",\n",
    "    function_choice_behavior=FunctionChoiceBehavior.Auto() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:87\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     86\u001b[0m         settings_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m---> 87\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings_dict)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\openai\\resources\\chat\\completions.py:1720\u001b[0m, in \u001b[0;36mAsyncCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1719\u001b[0m validate_response_format(response_format)\n\u001b[1;32m-> 1720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m   1721\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1722\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[0;32m   1723\u001b[0m         {\n\u001b[0;32m   1724\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages,\n\u001b[0;32m   1725\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m   1726\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio\u001b[39m\u001b[38;5;124m\"\u001b[39m: audio,\n\u001b[0;32m   1727\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: frequency_penalty,\n\u001b[0;32m   1728\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_call\u001b[39m\u001b[38;5;124m\"\u001b[39m: function_call,\n\u001b[0;32m   1729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunctions\u001b[39m\u001b[38;5;124m\"\u001b[39m: functions,\n\u001b[0;32m   1730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogit_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: logit_bias,\n\u001b[0;32m   1731\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs,\n\u001b[0;32m   1732\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_completion_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_completion_tokens,\n\u001b[0;32m   1733\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_tokens,\n\u001b[0;32m   1734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[0;32m   1735\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodalities\u001b[39m\u001b[38;5;124m\"\u001b[39m: modalities,\n\u001b[0;32m   1736\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m   1737\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparallel_tool_calls\u001b[39m\u001b[38;5;124m\"\u001b[39m: parallel_tool_calls,\n\u001b[0;32m   1738\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m: prediction,\n\u001b[0;32m   1739\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpresence_penalty\u001b[39m\u001b[38;5;124m\"\u001b[39m: presence_penalty,\n\u001b[0;32m   1740\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning_effort\u001b[39m\u001b[38;5;124m\"\u001b[39m: reasoning_effort,\n\u001b[0;32m   1741\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m   1742\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: seed,\n\u001b[0;32m   1743\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mservice_tier\u001b[39m\u001b[38;5;124m\"\u001b[39m: service_tier,\n\u001b[0;32m   1744\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop,\n\u001b[0;32m   1745\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m\"\u001b[39m: store,\n\u001b[0;32m   1746\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream,\n\u001b[0;32m   1747\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream_options,\n\u001b[0;32m   1748\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[0;32m   1749\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_choice,\n\u001b[0;32m   1750\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[0;32m   1751\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_logprobs,\n\u001b[0;32m   1752\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[0;32m   1753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m   1754\u001b[0m         },\n\u001b[0;32m   1755\u001b[0m         completion_create_params\u001b[38;5;241m.\u001b[39mCompletionCreateParams,\n\u001b[0;32m   1756\u001b[0m     ),\n\u001b[0;32m   1757\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m   1758\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m   1759\u001b[0m     ),\n\u001b[0;32m   1760\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mChatCompletion,\n\u001b[0;32m   1761\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1762\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mAsyncStream[ChatCompletionChunk],\n\u001b[0;32m   1763\u001b[0m )\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\openai\\_base_client.py:1843\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1840\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1841\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1842\u001b[0m )\n\u001b[1;32m-> 1843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\openai\\_base_client.py:1537\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1537\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1538\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1539\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1540\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1541\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1542\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1543\u001b[0m )\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\openai\\_base_client.py:1638\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[0;32m   1637\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1638\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1640\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1641\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1642\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1646\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1647\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m ChatHistory()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get the response from the AI\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mawait\u001b[39;00m chat_completion\u001b[38;5;241m.\u001b[39mget_chat_message_contents(\n\u001b[0;32m      6\u001b[0m     chat_history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m      7\u001b[0m     settings\u001b[38;5;241m=\u001b[39mexecution_settings,\n\u001b[0;32m      8\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m      9\u001b[0m     arguments\u001b[38;5;241m=\u001b[39mKernelArguments(),\n\u001b[0;32m     10\u001b[0m ))[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\chat_completion_client_base.py:147\u001b[0m, in \u001b[0;36mChatCompletionClientBase.get_chat_message_contents\u001b[1;34m(self, chat_history, settings, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m use_span(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_auto_function_invocation_activity(kernel, settings), end_on_exit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m _:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m request_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior\u001b[38;5;241m.\u001b[39mmaximum_auto_invoke_attempts):\n\u001b[1;32m--> 147\u001b[0m         completions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_get_chat_message_contents(chat_history, settings)\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;66;03m# Get the function call contents from the chat message. There is only one chat message,\u001b[39;00m\n\u001b[0;32m    149\u001b[0m         \u001b[38;5;66;03m# which should be checked in the `_verify_function_choice_settings` method.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m         function_calls \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m completions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, FunctionCallContent)]\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\semantic_kernel\\utils\\telemetry\\model_diagnostics\\decorators.py:83\u001b[0m, in \u001b[0;36mtrace_chat_completion.<locals>.inner_trace_chat_completion.<locals>.wrapper_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(completion_func)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_decorator\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[ChatMessageContent]:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m completion_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     85\u001b[0m     completion_service: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatCompletionClientBase\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     86\u001b[0m     chat_history: ChatHistory \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_history\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_chat_completion_base.py:88\u001b[0m, in \u001b[0;36mOpenAIChatCompletionBase._inner_get_chat_message_contents\u001b[1;34m(self, chat_history, settings)\u001b[0m\n\u001b[0;32m     85\u001b[0m settings\u001b[38;5;241m.\u001b[39mmessages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_chat_history_for_request(chat_history)\n\u001b[0;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_id\n\u001b[1;32m---> 88\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(settings)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ChatCompletion)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[0;32m     90\u001b[0m response_metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_from_chat_response(response)\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:59\u001b[0m, in \u001b[0;36mOpenAIHandler._send_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mTEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mCHAT:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_completion_request(settings)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mai_model_type \u001b[38;5;241m==\u001b[39m OpenAIModelTypes\u001b[38;5;241m.\u001b[39mEMBEDDING:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "File \u001b[1;32mf:\\01_Learning\\SemanticKernel\\venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:104\u001b[0m, in \u001b[0;36mOpenAIHandler._send_completion_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    101\u001b[0m         ex,\n\u001b[0;32m    102\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to complete the prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    106\u001b[0m         ex,\n\u001b[0;32m    107\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion.AzureChatCompletion'> service failed to complete the prompt\", NotFoundError(\"Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\"))"
     ]
    }
   ],
   "source": [
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "\n",
    "# Get the response from the AI\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "    chat_history=history,\n",
    "    settings=execution_settings,\n",
    "    kernel=kernel,\n",
    "    arguments=KernelArguments(),\n",
    "))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error: https://learn.microsoft.com/en-gb/answers/questions/2139037/404-resource-not-found-error-when-azure-python-web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep dive into Semantic Kernel \n",
    "https://github.com/microsoft/semantic-kernel/tree/main/python/samples/concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
